{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this workbook, we will clean and process the user, business and reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kindly extract the user, business and reviews dataset from Yelp challenge dataset link: https://www.yelp.com/dataset/challenge, and place it into the '/GA-Capstone/0. Datasets/Yelp Challenge Dataset' folder before running the code in this workbook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also found in the data folder\n",
    "\n",
    "user_json = \"C:/Users/user/Capstone project/GA-Capstone/0. Datasets/Yelp Challenge Dataset/user.json\"\n",
    "review_json = \"C:/Users/user/Capstone project/GA-Capstone/0. Datasets/Yelp Challenge Dataset/review.json\"\n",
    "business_json = \"C:/Users/user/Capstone project/GA-Capstone/0. Datasets/Yelp Challenge Dataset/business.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192609"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_data = []\n",
    "with open(business_json, encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        biz_data.append(json.loads(line))\n",
    "len(biz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from json file, and specifically only take data points in restaurant category\n",
    "\n",
    "business_id = []\n",
    "city = []\n",
    "state = []\n",
    "stars = []\n",
    "review_count = []\n",
    "categories = []\n",
    "postal_code = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "pricerange = []\n",
    "is_open = []\n",
    "name = []\n",
    "opening_hours_mon = []\n",
    "opening_hours_tue = []\n",
    "opening_hours_wed = []\n",
    "opening_hours_thu = []\n",
    "opening_hours_fri = []\n",
    "opening_hours_sat = []\n",
    "opening_hours_sun = []\n",
    "\n",
    "\n",
    "# selected attributes\n",
    "outdoor_seat = []\n",
    "rest_good_for_groups = []\n",
    "good_kids = []\n",
    "rest_reserve = []\n",
    "rest_deliver = []\n",
    "noise_lvl = []\n",
    "credit_cards = []\n",
    "wifi = []\n",
    "alcohol = []\n",
    "\n",
    "attribute_types = ['OutdoorSeating',\n",
    "                   'RestaurantsGoodForGroups',\n",
    "                   'GoodForKids', \n",
    "                   'RestaurantReservations', \n",
    "                   'RestaurantDelivery',\n",
    "                   'NoiseLevel',\n",
    "                   'ByAppointmentOnly',\n",
    "                   'RestaurantsPriceRange2',\n",
    "                   'BusinessAcceptsCreditCards',\n",
    "                   'WiFi',\n",
    "                   'Alcohol']\n",
    "\n",
    "for entry in range(0, len(biz_data)): \n",
    "    try:\n",
    "        if \"Restaurants\" in biz_data[entry][\"categories\"]:\n",
    "            business_id.append(biz_data[entry]['business_id'])\n",
    "            name.append(biz_data[entry]['name'])\n",
    "            city.append(biz_data[entry]['city'])\n",
    "            state.append(biz_data[entry]['state'])\n",
    "            stars.append(biz_data[entry]['stars'])\n",
    "            postal_code.append(biz_data[entry]['postal_code'])\n",
    "            review_count.append(biz_data[entry]['review_count'])\n",
    "            categories.append(biz_data[entry]['categories'])\n",
    "            latitude.append(biz_data[entry]['latitude'])\n",
    "            longitude.append(biz_data[entry]['longitude'])\n",
    "            is_open.append(biz_data[entry]['is_open'])\n",
    "            \n",
    "            try:\n",
    "                if 'Monday' in biz_data[entry]['hours']:\n",
    "                    opening_hours_mon.append(biz_data[entry]['hours']['Monday'])\n",
    "                else:\n",
    "                    opening_hours_mon.append('NA')\n",
    "            except TypeError:\n",
    "                opening_hours_mon.append('NA')\n",
    "              \n",
    "            try:\n",
    "                if 'Tuesday' in biz_data[entry]['hours']:\n",
    "                    opening_hours_tue.append(biz_data[entry]['hours']['Tuesday'])\n",
    "                else:\n",
    "                    opening_hours_tue.append('NA')\n",
    "            except TypeError:\n",
    "                opening_hours_tue.append('NA')\n",
    "                \n",
    "            try:\n",
    "                if 'Wednesday' in biz_data[entry]['hours']:\n",
    "                    opening_hours_wed.append(biz_data[entry]['hours']['Wednesday'])\n",
    "                else:\n",
    "                    opening_hours_wed.append('NA')\n",
    "            except TypeError:\n",
    "                opening_hours_wed.append('NA')\n",
    "            \n",
    "            try:\n",
    "                if 'Thursday' in biz_data[entry]['hours']:\n",
    "                    opening_hours_thu.append(biz_data[entry]['hours']['Thursday'])\n",
    "                else:\n",
    "                    opening_hours_thu.append('NA')\n",
    "            except TypeError:\n",
    "                opening_hours_thu.append('NA')\n",
    "            \n",
    "            try:\n",
    "                if 'Friday' in biz_data[entry]['hours']:\n",
    "                    opening_hours_fri.append(biz_data[entry]['hours']['Friday'])\n",
    "                else:\n",
    "                    opening_hours_fri.append('NA')\n",
    "            except TypeError:\n",
    "                opening_hours_fri.append('NA')\n",
    "            \n",
    "            try:\n",
    "                if 'Saturday' in biz_data[entry]['hours']:\n",
    "                    opening_hours_sat.append(biz_data[entry]['hours']['Saturday'])\n",
    "                else:\n",
    "                    opening_hours_sat.append('NA')\n",
    "            except TypeError:\n",
    "                opening_hours_sat.append('NA')\n",
    "            \n",
    "            try:\n",
    "                if 'Sunday' in biz_data[entry]['hours']:\n",
    "                    opening_hours_sun.append(biz_data[entry]['hours']['Sunday'])\n",
    "                else:\n",
    "                    opening_hours_sun.append('NA')\n",
    "            except TypeError:\n",
    "                opening_hours_sun.append('NA')\n",
    "            \n",
    "            try:\n",
    "                if 'RestaurantsPriceRange2'in biz_data[entry]['attributes']:\n",
    "                    pricerange.append(biz_data[entry]['attributes']['RestaurantsPriceRange2'])\n",
    "                else:\n",
    "                    pricerange.append('NA')\n",
    "            except TypeError:\n",
    "                pricerange.append('NA')\n",
    "            \n",
    "            try:\n",
    "                if 'RestaurantsGoodForGroups'in biz_data[entry]['attributes']:\n",
    "                    rest_good_for_groups.append(biz_data[entry]['attributes']['RestaurantsGoodForGroups'])\n",
    "                else:\n",
    "                    rest_good_for_groups.append('NA')\n",
    "            except TypeError:\n",
    "                rest_good_for_groups.append('NA')\n",
    "    \n",
    "    \n",
    "            try:\n",
    "                if 'OutdoorSeating'in biz_data[entry]['attributes']:\n",
    "                    outdoor_seat.append(biz_data[entry]['attributes']['OutdoorSeating'])\n",
    "                else:\n",
    "                    outdoor_seat.append('NA')\n",
    "            except TypeError:\n",
    "                outdoor_seat.append('NA')\n",
    "\n",
    "            try: \n",
    "                if 'GoodForKids' in biz_data[entry]['attributes']:\n",
    "                    good_kids.append(biz_data[entry]['attributes']['GoodForKids'])\n",
    "                else:\n",
    "                    good_kids.append('NA')\n",
    "            except TypeError:\n",
    "                good_kids.append('NA')\n",
    "\n",
    "            try: \n",
    "                if 'RestaurantsReservations' in biz_data[entry]['attributes']:\n",
    "                    rest_reserve.append(biz_data[entry]['attributes']['RestaurantsReservations'])\n",
    "                else:\n",
    "                    rest_reserve.append('NA')\n",
    "            except TypeError:\n",
    "                rest_reserve.append('NA')\n",
    "\n",
    "            try:  \n",
    "                if 'RestaurantsDelivery' in biz_data[entry]['attributes']:\n",
    "                    rest_deliver.append(biz_data[entry]['attributes']['RestaurantsDelivery'])\n",
    "                else:\n",
    "                    rest_deliver.append('NA') \n",
    "            except TypeError:\n",
    "                rest_deliver.append('NA')\n",
    "\n",
    "            try:\n",
    "                if 'NoiseLevel' in biz_data[entry]['attributes']:\n",
    "                    noise_lvl.append(biz_data[entry]['attributes']['NoiseLevel'])\n",
    "                else:\n",
    "                    noise_lvl.append('NA')\n",
    "            except TypeError:\n",
    "                noise_lvl.append('NA')\n",
    "\n",
    "            try:\n",
    "                if 'BusinessAcceptsCreditCards' in biz_data[entry]['attributes']:\n",
    "                    credit_cards.append(biz_data[entry]['attributes']['BusinessAcceptsCreditCards'])\n",
    "                else:\n",
    "                    credit_cards.append('NA')\n",
    "            except TypeError:\n",
    "                credit_cards.append('NA')\n",
    "\n",
    "            try:\n",
    "                if 'WiFi' in biz_data[entry]['attributes']:\n",
    "                    wifi.append(biz_data[entry]['attributes']['WiFi'])\n",
    "                else:\n",
    "                    wifi.append('NA')\n",
    "            except TypeError:\n",
    "                wifi.append('NA')\n",
    "\n",
    "            try:\n",
    "                if 'Alcohol' in biz_data[entry]['attributes']:\n",
    "                    alcohol.append(biz_data[entry]['attributes']['Alcohol'])\n",
    "                else:\n",
    "                    alcohol.append('NA')\n",
    "            except TypeError:\n",
    "                alcohol.append('NA')\n",
    "\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the business datapoints gathered in the previous step into a dataframe\n",
    "\n",
    "business_data = {'business_id': business_id,\n",
    "                 'name': name,\n",
    "                 'city': city,\n",
    "                 'state': state,\n",
    "                 'stars': stars,\n",
    "                 'review_count': review_count,\n",
    "                 'categories': categories,\n",
    "                 'postal_code': postal_code,\n",
    "                 'latitude': latitude,\n",
    "                 'longitude': longitude,\n",
    "                 'pricerange': pricerange,\n",
    "                 'is_open': is_open,\n",
    "                 \n",
    "                 'opening_hours_mon': opening_hours_mon,\n",
    "                 'opening_hours_tue': opening_hours_tue,\n",
    "                 'opening_hours_wed': opening_hours_wed,\n",
    "                 'opening_hours_thu': opening_hours_thu,\n",
    "                 'opening_hours_fri': opening_hours_fri,\n",
    "                 'opening_hours_sat': opening_hours_sat,\n",
    "                 'opening_hours_sun': opening_hours_sun,\n",
    "\n",
    "                 'outdoor_seat': outdoor_seat,\n",
    "                 'rest_good_for_groups': rest_good_for_groups,\n",
    "                 'good_kids': good_kids,\n",
    "                 'rest_reserve': rest_reserve,\n",
    "                 'rest_deliver': rest_deliver,\n",
    "                 'noise_lvl': noise_lvl,\n",
    "                 'credit_cards': credit_cards,\n",
    "                 'wifi': wifi,\n",
    "                 'alcohol': alcohol}\n",
    "\n",
    "business_data_df = pd.DataFrame(business_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Narrow down the scope to only Las Vegas restaurants so that dataset to work with is more manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Select only Las Vegas restaurants\n",
    "\n",
    "business_data_1 = business_data_df[(business_data_df['city'] == 'Las Vegas')]\n",
    "\n",
    "# drop city column and state column since the scope is narrowed to only Las Vegas\n",
    "\n",
    "business_data_1.drop(['city', 'state'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check on all columns\n",
    "# Drop columns with NA or None to reduce number of cols to work with\n",
    "\n",
    "# clean price range of restaurants\n",
    "business_data_1 = business_data_1[~((business_data_1['pricerange'] == 'NA') | (business_data_1['pricerange'] == 'None'))]\n",
    "\n",
    "# clean outdoor seat column\n",
    "business_data_1 = business_data_1[~((business_data_1['outdoor_seat'] == 'NA') | (business_data_1['outdoor_seat'] == 'None'))]\n",
    "business_data_1['outdoor_seat'] = business_data_1['outdoor_seat'].map(lambda x: 1 if x == 'True' else 0)\n",
    "\n",
    "# clean restaurant good for groups column\n",
    "business_data_1 = business_data_1[~((business_data_1['rest_good_for_groups'] == 'NA') | (business_data_1['rest_good_for_groups'] == 'None'))]\n",
    "business_data_1['rest_good_for_groups'] = business_data_1['rest_good_for_groups'].map(lambda x: 1 if x == 'True' else 0)\n",
    "\n",
    "# clean good_kids column\n",
    "business_data_1 = business_data_1[~((business_data_1['good_kids'] == 'NA') | (business_data_1['good_kids'] == 'None'))]\n",
    "business_data_1['good_kids'] = business_data_1['good_kids'].map(lambda x: 1 if x == 'True' else 0)\n",
    "\n",
    "# clean rest_reserve column\n",
    "business_data_1 = business_data_1[~((business_data_1['rest_reserve'] == 'NA') | (business_data_1['rest_reserve'] == 'None'))]\n",
    "business_data_1['rest_reserve'] = business_data_1['rest_reserve'].map(lambda x: 1 if x == 'True' else 0)\n",
    "\n",
    "# clean rest_deliver column\n",
    "business_data_1 = business_data_1[~((business_data_1['rest_deliver'] == 'NA') | (business_data_1['noise_lvl'] == 'None'))]\n",
    "business_data_1['rest_deliver'] = business_data_1['rest_deliver'].map(lambda x: 1 if x == 'True' else 0)\n",
    "\n",
    "# clean noise_lvl column\n",
    "business_data_1 = business_data_1[~((business_data_1['noise_lvl'] == 'NA') | (business_data_1['noise_lvl'] == 'None'))]\n",
    "business_data_1['noise_lvl'] = business_data_1['noise_lvl'].map(lambda x: str(x).replace(\"u'\", \"\").replace(\"'\", \"\"))\n",
    "\n",
    "# clean credit card column\n",
    "business_data_1 = business_data_1[~((business_data_1['credit_cards'] == 'NA') | (business_data_1['credit_cards'] == 'None'))]\n",
    "business_data_1['credit_cards'] = business_data_1['credit_cards'].map(lambda x: 1 if x == 'True' else 0)\n",
    "                                                                                                                                                           \n",
    "# if restaurant has wifi\n",
    "business_data_1['wifi'] = business_data_1['wifi'].map(lambda x: str(x).replace(\"u'\", \"\").replace(\"'\", \"\").replace('None', 'no'))\n",
    "business_data_1 = business_data_1[~((business_data_1['wifi'] == 'NA') | (business_data_1['wifi'] == 'None'))]\n",
    "business_data_1['wifi'] = business_data_1['wifi'].map(lambda x: 0 if x == 'no' else 1)\n",
    "\n",
    "# if restaurant has alcohol\n",
    "business_data_1['alcohol'] = business_data_1['alcohol'].map(lambda x: str(x).replace(\"u'\", \"\").replace(\"'\", \"\").replace('None', 'none'))\n",
    "business_data_1 = business_data_1[~((business_data_1['alcohol'] == 'NA') | (business_data_1['alcohol'] == 'None'))]\n",
    "business_data_1['alcohol'] = business_data_1['alcohol'].map(lambda x: 0 if x == 'none' else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert pricerange data to int\n",
    "\n",
    "business_data_1['pricerange'] = business_data_1['pricerange'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop opening hours data\n",
    "business_data_1.drop(['opening_hours_mon', 'opening_hours_tue', 'opening_hours_wed','opening_hours_thu'\n",
    "                     ,'opening_hours_fri', 'opening_hours_sat', 'opening_hours_sun'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the word 'Restaurants', 'Food' from the categories column\n",
    "\n",
    "business_data_1['categories'] = business_data_1['categories'].map(lambda x: str(x).replace(\"Restaurants, \", \"\")\n",
    "                                                                                    .replace(\"Restaurants\", \"\")\n",
    "                                                                                    .replace(\", Food,\", \",\")\n",
    "                                                                                    .rstrip(\", \")\n",
    "                                                                                    .rstrip(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop businesses without postal code\n",
    "business_data_1 = business_data_1[~business_data_1['postal_code'].isnull()].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Perform some feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform some feature engineering on opening hours\n",
    "\n",
    "# if restaurant is open 24 hrs\n",
    "business_data_1['open_24hrs'] = business_data_1['opening_hours_fri'].apply(lambda x: 1 if x == '0:0-0:0' else 0)\n",
    "\n",
    "# if restaurant serves breakfast - implied by opening hours\n",
    "def openbf(x):\n",
    "    if x != 'NA':\n",
    "        if x == '0:0-0:0':\n",
    "            x = 1\n",
    "        elif (int(x.split(':', 1)[0]) < 12) & (int(x.split(':', 1)[0]) > 5):\n",
    "            x = 1\n",
    "        else:\n",
    "            x = 0\n",
    "    else:\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "business_data_1['serves_breakfast'] = business_data_1['opening_hours_fri'].apply(lambda x: openbf(x))\n",
    "\n",
    "\n",
    "# if restaurant serves lunch - implied by opening hours\n",
    "def openlunch(x):\n",
    "    if x != 'NA':\n",
    "        if int(x.split(':', 1)[0]) >= 14:\n",
    "            x = 0\n",
    "        else:\n",
    "            x = 1\n",
    "            \n",
    "    # Give benefit of doubt that restaurants that are NA should be open for lunch\n",
    "    else:\n",
    "        x = 1\n",
    "    return x\n",
    "\n",
    "business_data_1['serves_lunch'] = business_data_1['opening_hours_fri'].apply(lambda x: openlunch(x))\n",
    "\n",
    "\n",
    "# if restaurant serves dinner - implied by closing hours\n",
    "\n",
    "def opendinner(x):\n",
    "    if x != 'NA':\n",
    "        if (int(x.split('-')[1].split(':')[0]) < 18) & (int(x.split('-')[1].split(':')[0]) > 7):\n",
    "            x = 0\n",
    "        else:\n",
    "            x = 1\n",
    "    else:\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "business_data_1['serves_dinner'] = business_data_1['opening_hours_fri'].apply(lambda x: opendinner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column indicating if business is a chain\n",
    "counts = business_data_1['name'].value_counts()\n",
    "\n",
    "business_data_1['is_chain'] = business_data_1['name'].apply(lambda x: 1 if x in counts[counts > 1].index else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4284"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of business id of all restaurants \n",
    "\n",
    "restaurant_ids = business_data_1['business_id'].tolist()\n",
    "\n",
    "len(restaurant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_data_1.to_csv('business_data_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Creating a unique legible name for every business (instead of just using business ID)\n",
    "\n",
    "business_data_1['unique_store_id'] = business_data_1['name'] + ' (' + 'Outlet - ' + business_data_1['postal_code'] + ')'\n",
    "\n",
    "business_data_1['unique_store_id_1'] = np.nan\n",
    "\n",
    "for index in range(0, business_data_1.shape[0]):\n",
    "    if business_data_1.loc[index, 'is_chain'] == 1:\n",
    "        business_data_1.loc[index, 'unique_store_id_1'] = business_data_1.loc[index, 'unique_store_id']\n",
    "    else:\n",
    "        business_data_1.loc[index, 'unique_store_id_1'] = business_data_1.loc[index, 'name']\n",
    "        \n",
    "business_data_1.rename(columns = {\"unique_store_id\": \"unique_store_id_test\"}, inplace = True) \n",
    "business_data_1.rename(columns = {\"unique_store_id_1\": \"unique_store_id\"}, inplace = True)\n",
    "\n",
    "business_data_1.drop(['unique_store_id_test'], axis = 1, inplace = True)\n",
    "business_data_1.sort_values(by = ['unique_store_id'], inplace = True)\n",
    "business_data_1.reset_index(drop = True)\n",
    "\n",
    "# Create intermediate column 'cumcount' to count num of outlets\n",
    "business_data_1['cumcount'] = business_data_1.groupby('unique_store_id').cumcount() + 1\n",
    "\n",
    "\n",
    "\n",
    "# add outlet count\n",
    "business_data_1['unique_store_id_outlet'] = np.nan\n",
    "\n",
    "for index in range(0, business_data_1.shape[0]):\n",
    "    if business_data_1.loc[index, 'is_chain'] == 0:\n",
    "        business_data_1.loc[index, 'unique_store_id_outlet'] = 0\n",
    "    else: \n",
    "        business_data_1.loc[index, 'unique_store_id_outlet'] = business_data_1.loc[index, 'cumcount']\n",
    "        \n",
    "        \n",
    "# insert outlet no. into unique_store_id for store chains\n",
    "\n",
    "for i in range(0, business_data_1.shape[0]):\n",
    "    if business_data_1['unique_store_id_outlet'][i] >= 1.0:\n",
    "        business_data_1['unique_store_id'][i] = business_data_1['name'][i] + ' (' + 'Outlet ' + str(business_data_1['cumcount'][i]) + ' - ' + str(business_data_1['postal_code'][i]) + ')'\n",
    "    else:\n",
    "        business_data_1['unique_store_id'][i] = business_data_1['name'][i]\n",
    "        \n",
    "        \n",
    "# drop intermediate columns 'unique store id outlet' and 'cumcount'\n",
    "business_data_1.drop(['unique_store_id_outlet', 'cumcount'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_data_1.reset_index(drop= True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file to CSV to create a save copy\n",
    "\n",
    "business_data_1.to_csv('business_data_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_data_1 = pd.read_csv('business_data_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json into python dictionary\n",
    "\n",
    "data = []\n",
    "with open(review_json, encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'Q1sbwvVQXV2734tPgoKj4Q',\n",
       " 'user_id': 'hG7b0MtEbXx5QzbzE6C_VA',\n",
       " 'business_id': 'ujmEBvifdJM6h6RLv4wQIg',\n",
       " 'stars': 1.0,\n",
       " 'useful': 6,\n",
       " 'funny': 1,\n",
       " 'cool': 0,\n",
       " 'text': 'Total bill for this horrible service? Over $8Gs. These crooks actually had the nerve to charge us $69 for 3 pills. I checked online the pills can be had for 19 cents EACH! Avoid Hospital ERs at all costs.',\n",
       " 'date': '2013-05-07 04:34:36'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from json file and populate data into down into individual lists. \n",
    "# Ignore useful, funny and cool columns\n",
    "\n",
    "reviewid = []\n",
    "businessid= []\n",
    "userid = []\n",
    "stars = []\n",
    "text = []\n",
    "date = []\n",
    "\n",
    "for entry in range(0, len(data)):     \n",
    "    reviewid.append(data[entry]['review_id'])\n",
    "    businessid.append(data[entry]['business_id'])\n",
    "    userid.append(data[entry]['user_id'])\n",
    "    stars.append(data[entry]['stars'])\n",
    "    text.append(data[entry]['text'])\n",
    "    date.append(data[entry]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the datapoints from the reviews dataset the previous step into a dataframe\n",
    "\n",
    "data = {'review_id': reviewid,\n",
    "        'business_id': businessid,\n",
    "        'user_id': userid,\n",
    "        'stars': stars,\n",
    "        'text': text,\n",
    "        'date': date}\n",
    "\n",
    "review_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4201684, 7)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label and remove non-restaurant reviews\n",
    "review_data['is_restaurant'] = review_data['business_id'].apply(lambda x: 1 if x in restaurant_ids else 0)\n",
    "\n",
    "# Filter by restaurant only reviews\n",
    "review_data = review_data[review_data['is_restaurant'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only date from date column - ignore time\n",
    "\n",
    "review_data['date'] = pd.to_datetime(review_data['date'].apply(lambda x: str(x)[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485586, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reviews dataset to csv\n",
    "\n",
    "review_data.to_csv('review_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = pd.read_csv('review_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Load user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637138"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = []\n",
    "with open(user_json, encoding = 'utf8') as f:\n",
    "    for line in f:\n",
    "        data3.append(json.loads(line))\n",
    "len(data3) #1637138 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only selected the following 4 attributes\n",
    "\n",
    "userid = []\n",
    "review_count = []\n",
    "average_stars = []\n",
    "yelping_since = []\n",
    "\n",
    "for entry in range(0, len(data3)):     \n",
    "    userid.append(data3[entry]['user_id'])\n",
    "    average_stars.append(data3[entry]['average_stars'])\n",
    "    review_count.append(data3[entry]['review_count'])\n",
    "    yelping_since.append(data3[entry]['yelping_since'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = {'user_id':userid ,\n",
    "         'average_stars':average_stars,\n",
    "         'review_count':review_count,\n",
    "         'yelping_since':yelping_since,\n",
    "         'review_count':review_count}\n",
    "\n",
    "user_data  = pd.DataFrame(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1637138, 4)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>4.03</td>\n",
       "      <td>95</td>\n",
       "      <td>2013-10-08 23:11:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4XChL029mKr5hydo79Ljxg</td>\n",
       "      <td>3.63</td>\n",
       "      <td>33</td>\n",
       "      <td>2013-02-21 22:29:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bc8C_eETBWL0olvFSJJd0w</td>\n",
       "      <td>3.71</td>\n",
       "      <td>16</td>\n",
       "      <td>2013-10-04 00:16:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dD0gZpBctWGdWo9WlGuhlA</td>\n",
       "      <td>4.85</td>\n",
       "      <td>17</td>\n",
       "      <td>2014-05-22 15:57:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MM4RJAeH6yuaN8oZDSt0RA</td>\n",
       "      <td>4.08</td>\n",
       "      <td>361</td>\n",
       "      <td>2013-10-23 07:02:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0rK89TS8xqy1wI4nYI1wfw</td>\n",
       "      <td>4.20</td>\n",
       "      <td>214</td>\n",
       "      <td>2011-06-23 08:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEtzbpgA2BFBrC0y0sCbfw</td>\n",
       "      <td>4.39</td>\n",
       "      <td>1122</td>\n",
       "      <td>2006-02-15 18:29:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KGuqerdeNhxzXZEyBaqqSw</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6</td>\n",
       "      <td>2014-06-07 01:50:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T0gWkTHWRChVUe_Dn1F8nw</td>\n",
       "      <td>4.21</td>\n",
       "      <td>859</td>\n",
       "      <td>2005-07-20 22:38:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NQffx45eJaeqhFcMadKUQA</td>\n",
       "      <td>4.53</td>\n",
       "      <td>124</td>\n",
       "      <td>2008-12-10 22:59:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  average_stars  review_count        yelping_since\n",
       "0  l6BmjZMeQD3rDxWUbiAiow           4.03            95  2013-10-08 23:11:33\n",
       "1  4XChL029mKr5hydo79Ljxg           3.63            33  2013-02-21 22:29:06\n",
       "2  bc8C_eETBWL0olvFSJJd0w           3.71            16  2013-10-04 00:16:10\n",
       "3  dD0gZpBctWGdWo9WlGuhlA           4.85            17  2014-05-22 15:57:30\n",
       "4  MM4RJAeH6yuaN8oZDSt0RA           4.08           361  2013-10-23 07:02:50\n",
       "5  0rK89TS8xqy1wI4nYI1wfw           4.20           214  2011-06-23 08:05:13\n",
       "6  TEtzbpgA2BFBrC0y0sCbfw           4.39          1122  2006-02-15 18:29:35\n",
       "7  KGuqerdeNhxzXZEyBaqqSw           4.33             6  2014-06-07 01:50:09\n",
       "8  T0gWkTHWRChVUe_Dn1F8nw           4.21           859  2005-07-20 22:38:17\n",
       "9  NQffx45eJaeqhFcMadKUQA           4.53           124  2008-12-10 22:59:45"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1637138 entries, 0 to 1637137\n",
      "Data columns (total 4 columns):\n",
      "user_id          1637138 non-null object\n",
      "average_stars    1637138 non-null float64\n",
      "review_count     1637138 non-null int64\n",
      "yelping_since    1637138 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(1)\n",
      "memory usage: 50.0+ MB\n"
     ]
    }
   ],
   "source": [
    "user_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save user file to csv\n",
    "\n",
    "user_data.to_csv('user_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user_data dataset\n",
    "\n",
    "user_data = pd.read_csv('user_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Load all datasets into sqlite3 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load business, reviews and user datasets\n",
    "\n",
    "business_data_1 = pd.read_csv('business_data_1.csv')\n",
    "review_data = pd.read_csv('review_data.csv')\n",
    "user_data = pd.read_csv('user_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4284, 25)\n",
      "(2485586, 7)\n",
      "(1637138, 4)\n"
     ]
    }
   ],
   "source": [
    "print(business_data_1.shape)\n",
    "print(review_data.shape)\n",
    "print(user_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data into sqlite3\n",
    "\n",
    "conn = sqlite3.connect('yelp.db')\n",
    "business_data_1.to_sql('business', con=conn, if_exists='replace')\n",
    "review_data.to_sql('reviews', con=conn, if_exists='replace')\n",
    "user_data.to_sql('users', con=conn, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_test",
   "language": "python",
   "name": "capstone_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
